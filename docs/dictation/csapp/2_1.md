# 2.1 Information Storage

Rather than accessing individual bits in memory, most computers use blocks of
8 bits, or bytes, as the smallest addressable unit of memory. A machine-level
program views memory as a very large array of bytes, referred to as **virtual memory**. 
Every byte of memory is identified by a unique number, known as its
address, and the set of all possible addresses is known as the **virtual address space**.
As indicated by its name, this virtual address space is just a conceptual image
presented to the machine-level program. The actual implementation (presented
in Chapter 9) uses a combination of dynamic random access memory (DRAM),
flash memory, disk storage, special hardware, and operating system software to
provide the program with what appears to be a monolithic byte array.

In subsequent chapters, we will cover how the compiler and run-time system
partitions this memory space into more manageable units to store the different
program objects, that is, program data, instructions, and control information.
Various mechanisms are used to allocate and manage the storage for different
parts of the program. This management is all performed within the virtual address
space. For example, the value of a pointer in C—whether it points to an integer,
a structure, or some other program object—is the virtual address of the first byte
of some block of storage. The C compiler also associates type information with
each pointer, so that it can generate different machine-level code to access the
value stored at the location designated by the pointer depending on the type of
that value. Although the C compiler maintains this type information, the actual
machine-level program it generates has no information about data types. It simply
treats each program object as a block of bytes and the program itself as a sequence
of bytes.

## 2.1.1 Hexadecimal Notation

A single byte consists of 8 bits. In binary notation, its value ranges from 00000000<sub>2</sub>
to 11111111<sub>2</sub>. When viewed as a decimal integer, its value ranges from 0<sub>10</sub> to 255<sub>10</sub>.
Neither notation is very convenient for describing bit patterns. Binary notation
is too verbose, while with decimal notation it is tedious to convert to and from
bit patterns. Instead, we write bit patterns as base-16, or **hexadecimal** numbers.
Hexadecimal (or simply “hex”) uses digits ‘0’ through ‘9’ along with characters
‘A’ through ‘F’ to represent 16 possible values. Figure 2.2 shows the decimal and
binary values associated with the 16 hexadecimal digits. Written in hexadecimal,
the value of a single byte can range from 00<sub>16</sub> to FF<sub>16</sub>.

In C, numeric constants starting with `0x` or `0X` are interpreted as being in
hexadecimal. The characters ‘A’ through ‘F’ may be written in either upper- or
lowercase. For example, we could write the number FA1D37B<sub>16</sub> as `0xFA1D37B`, as
`0xfa1d37b`, or even mixing upper- and lowercase (e.g., `0xFa1D37b`). We will use
the C notation for representing hexadecimal values in this book.

A common task in working with machine-level programs is to manually convert between decimal, binary, and hexadecimal representations of bit patterns. Converting between binary and hexadecimal is straightforward, since it can be
performed one hexadecimal digit at a time. Digits can be converted by referring
to a chart such as that shown in Figure 2.2. One simple trick for doing the conversion in your head is to memorize the decimal equivalents of hex digits A, C, and F.The hex values B, D, and E can be translated to decimal by computing their values
relative to the first three.

|               |      |      |      |      |      |      |      |      |
| ------------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| Hex digit     | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    |
| Decimal value | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    |
| Binary value  | 0000 | 0001 | 0010 | 0011 | 0100 | 0101 | 0110 | 0111 |
| Hex digit     | 8    | 9    | A    | B    | C    | D    | E    | F    |
| Decimal value | 8    | 9    | 10   | 11   | 12   | 13   | 14   | 15   |
| Binary value  | 1000 | 1001 | 1010 | 1011 | 1100 | 1101 | 1110 | 1111 |

For example, suppose you are given the number 0x173A4C. You can convert
this to binary format by expanding each hexadecimal digit, as follows:

|             |      |      |      |      |      |      |
| ----------- | ---- | ---- | ---- | ---- | ---- | ---- |
| Hexadecimal | 1    | 7    | 3    | A    | 4    | C    |
| Binary      | 0001 | 0111 | 0011 | 1010 | 0100 | 1100 |

This gives the binary representation 000101110011101001001100.

Conversely, given a binary number 1111001010110110110011, you convert it
to hexadecimal by first splitting it into groups of 4 bits each. Note, however, that if
the total number of bits is not a multiple of 4, you should make the leftmost group
be the one with fewer than 4 bits, effectively padding the number with leading
zeros. Then you translate each group of bits into the corresponding hexadecimal
digit:

|             |     |      |      |      |      |      |
| ----------- | --- | ---- | ---- | ---- | ---- | ---- |
| Binary      | 11  | 1100 | 1010 | 1101 | 1011 | 0011 |
| Hexadecimal | 3   | C    | A    | D    | B    | 3    |

## 2.1.2 Data Sizes

Every computer has a word size, indicating the nominal size of pointer data. Since
a virtual address is encoded by such a word, the most important system parameter
determined by the word size is the maximum size of the virtual address space. That
is, for a machine with a w-bit word size, the virtual addresses can range from 0 to
2<sup>w</sup> − 1, giving the program access to at most 2<sup>w</sup> bytes.


In recent years, there has been a widespread shift from machines with 32-
bit word sizes to those with word sizes of 64 bits. This occurred first for high-end
machines designed for large-scale scientific and database applications, followed
by desktop and laptop machines, and most recently for the processors found in
smartphones. A 32-bit word size limits the virtual address space to 4 gigabytes
(written 4 GB), that is, just over 4 × 10<sup>9</sup> bytes. Scaling up to a 64-bit word size
leads to a virtual address space of 16 exabytes, or around 1.84 × 10<sup>19</sup> bytes.

Most 64-bit machines can also run programs compiled for use on 32-bit machines, a form of backward compatibility. So, for example, when a program prog.c
is compiled with the directive

```bash
linux> gcc -m32 prog.c
```

then this program will run correctly on either a 32-bit or a 64-bit machine. On the
other hand, a program compiled with the directive

```bash
linux> gcc -m64 prog.c
```

will only run on a 64-bit machine. We will therefore refer to programs as being
either “32-bit programs” or “64-bit programs,” since the distinction lies in how a
program is compiled, rather than the type of machine on which it runs.

Computers and compilers support multiple data formats using different ways
to encode data, such as integers and floating point, as well as different lengths.
For example, many machines have instructions for manipulating single bytes, as
well as integers represented as 2-, 4-, and 8-byte quantities. They also support
floating-point numbers represented as 4- and 8-byte quantities.

The C language supports multiple data formats for both integer and floating-point data. 
Figure 2.3 shows the number of bytes typically allocated for different C
data types. (We discuss the relation between what is guaranteed by the C standard
versus what is typical in Section 2.2.) The exact numbers of bytes for some data
types depends on how the program is compiled. We show sizes for typical 32-bit
and 64-bit programs. Integer data can be either signed, able to represent negative,
zero, and positive values, or unsigned, only allowing nonnegative values. Data
type char represents a single byte. Although the name char derives from the fact
that it is used to store a single character in a text string, it can also be used to store
integer values. Data types short, int, and long are intended to provide a range of
sizes. Even when compiled for 64-bit systems, data type int is usually just 4 bytes.
Data type long commonly has 4 bytes in 32-bit programs and 8 bytes in 64-bit
programs

| Signed        | Unsigned       | 32-bit | 64-bit |
| ------------- | -------------- | ------ | ------ |
| [signed] char | unsigned char  | 1      | 1      |
| short         | unsigned short | 2      | 2      |
| int           | unsigned       | 4      | 4      |
| long          | unsigned long  | 4      | 8      |
| int32_t       | uint32_t       | 4      | 4      |
| int64_t       | uint64_t       | 8      | 8      |
| char *        |                | 4      | 8      |
| float         |                | 4      | 4      |
| double        |                | 8      | 8      |


To avoid the vagaries of relying on “typical” sizes and different compiler settings, ISO C99 introduced a class of data types where the data sizes are fixed
regardless of compiler and machine settings. Among these are data types int32_t
and int64_t, having exactly 4 and 8 bytes, respectively. Using fixed-size integer
types is the best way for programmers to have close control over data representations.

Most of the data types encode signed values, unless prefixed by the keyword
unsigned or using the specific unsigned declaration for fixed-size data types. The
exception to this is data type char. Although most compilers and machines treat
these as signed data, the C standard does not guarantee this. Instead, as indicated
by the square brackets, the programmer should use the declaration signed char
to guarantee a 1-byte signed value. In many contexts, however, the program’s
behavior is insensitive to whether data type char is signed or unsigned.

The C language allows a variety of ways to order the keywords and to include
or omit optional keywords. As examples, all of the following declarations have
identical meaning:

```cpp
unsigned long a;
unsigned long int b;
long unsigned c;
long unsigned int d;
```

We will consistently use the forms found in Figure 2.3.

Figure 2.3 also shows that a pointer (e.g., a variable declared as being of
type char *) uses the full word size of the program. Most machines also support
two different floating-point formats: single precision, declared in C as float,
and double precision, declared in C as double. These formats use 4 and 8 bytes,
respectively.

Programmers should strive to make their programs portable across different
machines and compilers. One aspect of portability is to make the program insensitive to the exact sizes of the different data types. 
The C standards set lower bounds on the numeric ranges of the different data types, as will be covered later, but there
are no upper bounds (except with the fixed-size types). With 32-bit machines and 32-bit programs being the dominant combination from around 1980 until around 2010, 
many programs have been written assuming the allocations listed for 32-bit programs in Figure 2.3. 
With the transition to 64-bit machines, many hidden word size dependencies have arisen as bugs in migrating these programs to new
machines. For example, many programmers historically assumed that an object
declared as type int could be used to store a pointer. This works fine for most
32-bit programs, but it leads to problems for 64-bit programs.

## 2.1.3 Addressing and Byte Ordering